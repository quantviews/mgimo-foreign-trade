# Документация для `merge_processed_data.py`

Этот документ описывает работу скрипта `merge_processed_data.py`, который является финальным шагом в процессе объединения данных о внешней торговле из различных источников.

## Описание

Скрипт `merge_processed_data.py` предназначен для объединения всех обработанных наборов данных (в формате `.parquet` из папки `data_processed/`) в единую базу данных DuckDB. Он также позволяет опционально включать данные из базы Comtrade для стран, по которым отсутствуют национальные данные, и предоставляет гибкие опции фильтрации.

Скрипт включает строгую валидацию данных на этапе загрузки, что гарантирует целостность и соответствие данных ожидаемой схеме. При обнаружении ошибок валидации обработка файла прекращается с соответствующим сообщением об ошибке.

## Логика работы скрипта

Скрипт выполняет следующие шаги:

1.  **Поиск национальных данных**: Скрипт сканирует директорию `data_processed/` на наличие `.parquet` файлов (например, `ch_full.parquet`, `tr_full.parquet`).
    *   **Разделение файлов**: Файлы автоматически разделяются на две категории:
        *   **Обычные файлы данных**: файлы с национальными данными (например, `ch_full.parquet`, `tr_full.parquet`)
        *   **Fizob файлы**: файлы с расчетными физическими объемами, начинающиеся с `fizob` (например, `fizob2.parquet`, `fizob4.parquet`, `fizob6.parquet`)

2.  **Загрузка и валидация**: Каждый найденный `.parquet` файл загружается и проходит строгую проверку:
    *   **Валидация схемы**: Для обычных файлов данных структура данных (названия колонок, типы данных) сверяется с эталонной схемой, определенной в `EXPECTED_SCHEMA`. При обнаружении несоответствий (отсутствующие колонки, неправильные типы данных, невалидные значения в `NAPR` или пустые значения в `PERIOD`) файл отклоняется с ошибкой, и обработка прекращается.
    *   **Fizob файлы**: Файлы с расчетными физическими объемами, начинающиеся с `fizob` (например, `fizob2.parquet`, `fizob4.parquet`, `fizob6.parquet`), обрабатываются отдельно и сохраняются в отдельные таблицы в базе данных. Файлы, начинающиеся с `fizob_` (например, `fizob_2.parquet`), **пропускают валидацию схемы**, так как имеют отличную структуру данных. Файлы, начинающиеся с `fizob` без подчеркивания, также обрабатываются отдельно, но проходят валидацию схемы (если их структура не соответствует ожидаемой, они могут быть отклонены).
    *   **Генерация производных колонок**: Скрипт автоматически генерирует колонки `TNVED2`, `TNVED4`, `TNVED6`, `TNVED8` на основе основной колонки `TNVED`. 
        *   **Критически важно**: Производные колонки генерируются **ДО** нормализации основного кода, чтобы сохранить правильную структуру для кодов, начинающихся с нуля (например, коды уровня 01-10). Это гарантирует, что код `"0101010000"` будет иметь `TNVED2="01"`, а не `TNVED2="10"` после нормализации.
        *   **Нормализация кодов TNVED**: После генерации производных колонок основной код `TNVED` нормализуется для обеспечения единообразия:
            *   Сначала код дополняется нулями **справа** до 10 знаков, если он короче (например, `"870421"` → `"8704210000"`)
            *   Затем удаляются все ведущие нули (например, `"0000870421"` → `"870421"` → `"8704210000"`)
            *   Это гарантирует, что коды вида `"870421"` (8 знаков) и `"87042100"` (10 знаков) будут приведены к единому формату `"8704210000"` (10 знаков)
            *   При этом производные колонки (`TNVED2`, `TNVED4` и т.д.) уже сохранены с правильной структурой из исходного кода

3.  **Интеграция данных Comtrade (опционально)**:
    *   Если при запуске указан флаг `--include-comtrade`, скрипт подключается к базе данных `db/comtrade.db`.
    *   **Исключение дубликатов**: Чтобы избежать дублирования, скрипт сначала определяет, какие страны уже присутствуют в национальных данных (например, `CN`, `TR`, `IN`), и **исключает** их из запроса к Comtrade. После загрузки данных Comtrade выполняется дополнительная проверка для удаления любых записей, которые могли проскользнуть через фильтр.
    *   **Трансформация данных**: Данные из Comtrade преобразуются в соответствии с моделью данных проекта:
        *   Числовые M49-коды стран (`reporterCode`) переводятся в двухбуквенные ISO-коды (`STRANA`) с помощью `metadata/comtrate-partnerAreas.json`.
        *   Коды единиц измерения (`qtyUnitCode`, `altQtyUnitCode`) переводятся в их текстовые аббревиатуры (`EDIZM`) с помощью `metadata/comtradte-QuantityUnits.json`.
        *   **Выбор дополнительной единицы**: Скрипт анализирует основную и альтернативную единицы измерения. Так как вес в кг уже есть в колонке `NETTO`, для колонки `KOL` (доп. количество) выбирается не-весовая единица (например, штуки, литры).
        *   Направление торговли (`flowCode`) 'M' и 'X' преобразуется в 'ИМ' и 'ЭК'.
        *   Генерируются производные колонки `TNVED2`, `TNVED4`, `TNVED6`, `TNVED8` на основе `TNVED`. **Важно**: Производные колонки генерируются ДО нормализации, чтобы сохранить правильную структуру для кодов 01-10. Затем коды TNVED нормализуются так же, как и для национальных данных: сначала дополняются нулями справа до 10 знаков (если короче), затем удаляются ведущие нули.

4.  **Фильтрация данных**:
    *   **По году**: Если указан аргумент `--start-year`, все наборы данных (и национальные, и Comtrade) фильтруются, чтобы оставить только записи, начиная с указанного года.
    *   **По странам**: Если указан аргумент `--exclude-countries`, все записи, относящиеся к перечисленным странам, удаляются из итогового набора данных.

5.  **Объединение и очистка**:
    *   Все подготовленные наборы данных (национальные и Comtrade) объединяются в один DataFrame.
    *   В каждую запись добавляется колонка `SOURCE`, указывающая на источник (`national` или `comtrade`).
    *   Удаляются все строки, в которых отсутствует значение в колонке `NAPR` (направление торговли).

6.  **Стандартизация единиц измерения (EDIZM)**:
    *   Скрипт использует `metadata/edizm.csv` для приведения всех значений в колонке `EDIZM` к единому стандарту (например, 'kg', 'Kilogram', 'КИЛОГРАММ' будут приведены к одному общему виду).
    *   На основе стандартизированного значения заполняется колонка `EDIZM_ISO` соответствующим ISO-кодом.

7.  **Очистка дублирующих данных о весе**:
    *   **Обработка килограммов**: Чтобы избежать дублирования данных с колонкой `NETTO`, скрипт находит все строки, где дополнительная единица измерения (`EDIZM_ISO`) соответствует ISO-коду килограмма (166). В этих строках значения `KOL`, `EDIZM` и `EDIZM_ISO` устанавливаются в `NULL` (присваиваются по отдельности для каждой колонки).
    *   **Обработка тонн**: Скрипт применяет интеллектуальную логику для тонн (ISO-код 168):
        *   Если в строке указано `KOL` в тоннах, а колонка `NETTO` **пустая или равна нулю**, то значение из `KOL` конвертируется в кг (`KOL` * 1000) и записывается в `NETTO`. После этого `KOL`, `EDIZM` и `EDIZM_ISO` устанавливаются в `NULL` (присваиваются по отдельности для каждой колонки).
        *   Если же в строке `NETTO` **уже заполнено**, то `KOL` в тоннах считается дублирующей информацией, и значения `KOL`, `EDIZM` и `EDIZM_ISO` устанавливаются в `NULL` (присваиваются по отдельности для каждой колонки).

8.  **Сохранение результата**:
    *   Финальный, объединенный и очищенный DataFrame сохраняется в базу данных `db/unified_trade_data.duckdb`.
    *   Если база данных уже существует, она будет **полностью удалена** перед созданием новой для обеспечения чистоты данных.
    *   Данные сохраняются порциями (чанками) по 100,000 строк для экономии памяти.
    *   После сохранения выполняется проверка количества записей для подтверждения корректности сохранения.

9.  **Сохранение fizob файлов в отдельные таблицы**:
    *   Файлы с расчетными физическими объемами (`fizob*.parquet`) сохраняются в **отдельные таблицы** в базе данных, а не объединяются с основной таблицей `unified_trade_data`.
    *   Каждый fizob файл сохраняется в таблицу с именем, соответствующим имени файла (например, `fizob2.parquet` → таблица `fizob2`, `fizob4.parquet` → таблица `fizob4`, `fizob6.parquet` → таблица `fizob6`).
    *   Данные сохраняются порциями (чанками) по 100,000 строк для экономии памяти.
    *   Колонка `PERIOD` нормализуется и преобразуется в тип `DATE` для единообразия.
    *   После сохранения каждой таблицы выполняется проверка количества записей.

10. **Создание справочных таблиц**:
    *   **Нормализованная структура**: скрипт создает отдельные справочные таблицы для нормализации структуры базы данных:
        *   `country_reference` — таблица с соответствием ISO-кодов стран (`STRANA`) и их названий (`STRANA_NAME`) из `metadata/STRANA.csv`
        *   `tnved_reference` — таблица с кодами TNVED (`TNVED_CODE`), уровнями агрегации (`TNVED_LEVEL`: 2, 4, 6, 8, 10) и названиями (`TNVED_NAME`) из `metadata/tnved.csv`
    *   **Представление для удобства**: Создается представление `unified_trade_data_enriched`, которое автоматически объединяет основную таблицу со справочными таблицами, предоставляя все названия в удобном формате. Это позволяет использовать либо нормализованную структуру (для оптимизации), либо представление (для удобства в Superset).
    *   **Индексы**: На справочных таблицах создаются индексы для ускорения операций JOIN.

11. **Создание материализованной таблицы fizob_index**:
    *   Если в базе данных присутствуют таблицы с fizob данными (`fizob2`, `fizob4`, `fizob6`), скрипт автоматически создает материализованную таблицу `fizob_index`, которая объединяет все уровни fizob данных в единую структуру.
    *   **Структура таблицы `fizob_index`**:
        *   `STRANA` — код страны
        *   `NAPR` — направление торговли (ИМ/ЭК)
        *   `PERIOD` — период (дата)
        *   `tn_level` — уровень агрегации TNVED (0 = total, 2, 4, 6)
        *   `tn_code` — код TNVED (0 для агрегата по всем кодам, иначе TNVED2/4/6)
        *   `fizob` — значение физического объема
        *   `fizob_bp` — значение физического объема в базовом периоде
        *   `idx` — индекс (fizob / fizob_bp), NULL если fizob_bp = 0
    *   Таблица создается динамически: объединяются только те уровни (fizob2, fizob4, fizob6), которые присутствуют в базе данных.
    *   На таблице создаются индексы для ускорения запросов: `(STRANA, PERIOD)` и `(tn_level, tn_code)`.
    *   Таблица `fizob_index` предназначена для удобного использования в Superset, так как предоставляет единую точку доступа ко всем уровням fizob данных без необходимости делать UNION запросы вручную.

### Структура базы данных

База данных `unified_trade_data.duckdb` содержит следующие объекты:

*   **`unified_trade_data`** — основная таблица с данными о внешней торговле (без названий стран и TNVED для экономии места).
*   **`country_reference`** — справочная таблица с названиями стран (колонки: `STRANA`, `STRANA_NAME`).
*   **`tnved_reference`** — справочная таблица с названиями кодов TNVED (колонки: `TNVED_CODE`, `TNVED_LEVEL`, `TNVED_NAME`).
*   **`unified_trade_data_enriched`** — представление (VIEW), которое объединяет основную таблицу со справочными таблицами, добавляя все названия и ранжирование по периодам. Это удобно для использования в Superset, так как не требует ручного создания JOIN'ов.
    *   **Дополнительные колонки в представлении:**
        *   `COUNTRY_NAME` — название страны из справочника
        *   `TNVED2_NAME`, `TNVED4_NAME`, `TNVED6_NAME`, `TNVED8_NAME` — названия кодов TNVED соответствующих уровней
        *   `TNVED_NAME` — название полного кода TNVED (10 знаков), если доступно, иначе название уровня 8
        *   `period_rank` — порядковый номер записи по периоду для каждой комбинации страна-товар-направление (STRANA, TNVED, NAPR) (1 = самый последний месяц, 2 = предпоследний и т.д.). Это позволяет легко фильтровать последние N месяцев для каждого товарного потока независимо от того, когда обновляются данные.
*   **`fizob2`, `fizob4`, `fizob6`** (опционально) — отдельные таблицы с расчетными физическими объемами для соответствующих уровней агрегации TNVED (2, 4, 6 знака). Эти таблицы создаются только если в директории `data_processed/` присутствуют соответствующие `.parquet` файлы.
*   **`fizob_index`** (опционально) — материализованная таблица, объединяющая все уровни fizob данных (fizob2, fizob4, fizob6) в единую структуру для удобного использования в Superset.
    *   **Структура таблицы:**
        *   `STRANA` — код страны
        *   `NAPR` — направление торговли (ИМ/ЭК)
        *   `PERIOD` — период (дата)
        *   `tn_level` — уровень агрегации TNVED (0 = total, 2, 4, 6)
        *   `tn_code` — код TNVED (0 для агрегата, иначе TNVED2/4/6)
        *   `fizob` — значение физического объема
        *   `fizob_bp` — значение физического объема в базовом периоде
        *   `idx` — индекс (fizob / fizob_bp)
    *   Таблица создается автоматически при наличии хотя бы одной fizob таблицы в базе данных.
    *   На таблице созданы индексы для ускорения запросов: `(STRANA, PERIOD)` и `(tn_level, tn_code)`.

**Рекомендации по использованию:**
*   Для аналитики в Superset используйте представление `unified_trade_data_enriched` — оно содержит все необходимые данные с названиями.
*   Для получения последних 12 месяцев для каждого товарного потока используйте фильтр `WHERE period_rank <= 12`.
*   Для оптимизированных запросов, где названия не нужны, используйте таблицу `unified_trade_data` напрямую.
*   Для работы с физическими объемами в Superset используйте таблицу `fizob_index` — она предоставляет единую точку доступа ко всем уровням fizob данных без необходимости делать UNION запросы вручную.
*   При необходимости можно создавать собственные JOIN'ы между `unified_trade_data` и справочными таблицами для более гибкой настройки.
*   Для доступа к отдельным уровням fizob данных можно использовать таблицы `fizob2`, `fizob4`, `fizob6` напрямую.

12. **Вывод статистики**: В процессе работы скрипт выводит в консоль подробную статистику о результатах объединения, включая:
    *   Общее количество строк
    *   Количество уникальных стран
    *   Диапазон дат (минимальная и максимальная даты)
    *   Количество записей по каждому источнику (`national` или `comtrade`)
    *   Количество записей по каждой стране и источнику
    *   Распределение основных единиц измерения (`EDIZM`) по странам (топ-5 для каждой страны)
    *   Сообщение о том, что для обработки выбросов нужно запустить отдельный модуль `outlier_detection.py`

## Как запустить скрипт

Скрипт запускается из командной строки и поддерживает несколько аргументов для управления процессом объединения.

### Аргументы командной строки

*   `--include-comtrade` (опциональный): Флаг, указывающий на необходимость включения данных из Comtrade.
*   `--start-year <год>` (опциональный): Целое число. Если указано, в итоговый набор попадут только данные, начиная с этого года.
*   `--exclude-countries <ISO-код1> <ISO-код2> ...` (опциональный): Список двухбуквенных ISO-кодов стран, которые нужно исключить из финального набора данных.

### Примеры использования

**1. Простое объединение только национальных данных:**
```bash
python src/merge_processed_data.py
```

**2. Объединение национальных данных с добавлением Comtrade:**
```bash
python src/merge_processed_data.py --include-comtrade
```

**3. Объединение всех данных, начиная с 2019 года:**
```bash
python src/merge_processed_data.py --include-comtrade --start-year 2019
```

**4. Объединение всех данных, но с исключением Индии:**
```bash
python src/merge_processed_data.py --include-comtrade --exclude-countries IN
```

**5. Объединение данных за все года, исключая Китай и Турцию:**
```bash
python src/merge_processed_data.py --include-comtrade --exclude-countries CN TR
```

**Примечание**: Обработка выбросов теперь выполняется отдельным модулем `outlier_detection.py`. После объединения данных запустите:
```bash
python src/outlier_detection.py
```
Подробнее см. документацию `docs/outlier_detection-docs.md`.

## Технические детали и улучшения

### Валидация данных

Скрипт использует строгую валидацию на этапе загрузки данных:

*   **Проверка обязательных колонок**: Для обычных файлов данных все колонки из `EXPECTED_SCHEMA` должны присутствовать в файле.
*   **Проверка типов данных**: Типы данных должны точно соответствовать ожидаемым. При несоответствии файл отклоняется.
*   **Валидация значений**: 
    *   Колонка `NAPR` может содержать только значения 'ИМ' или 'ЭК'.
    *   Колонка `PERIOD` не может содержать пустые значения.
*   **Автоматическое преобразование**: Колонка `PERIOD` автоматически преобразуется в формат `datetime64[ns]` при необходимости.
*   **Исключения для fizob файлов**: Файлы с расчетными физическими объемами (`fizob*.parquet`) пропускают валидацию схемы, так как имеют отличную структуру данных и обрабатываются отдельно.

### Оптимизация производительности

*   **Эффективная генерация производных колонок**: Колонки `TNVED2`, `TNVED4`, `TNVED6`, `TNVED8` генерируются напрямую без предварительных проверок, что повышает производительность.
*   **Правильная нормализация кодов TNVED**: 
    *   Производные колонки генерируются **ДО** нормализации основного кода, что критически важно для сохранения правильной структуры кодов, начинающихся с нуля (01-10). Это предотвращает потерю данных для кодов уровня 01-10.
    *   Основной код `TNVED` нормализуется путем дополнения справа до 10 знаков (если короче), затем удаления ведущих нулей, что обеспечивает корректное сопоставление с справочником `tnved.csv` и правильную работу JOIN'ов в представлении `unified_trade_data_enriched`.
    *   Такой подход гарантирует, что код `"0101010000"` будет иметь `TNVED2="01"` (правильно), а не `TNVED2="10"` (неправильно, если бы нормализация происходила до генерации производных колонок).
*   **Оптимизированная обработка маппингов**: Использование `itertuples()` вместо `iterrows()` для более быстрой обработки справочников.
*   **Чанковая запись в базу данных**: Данные записываются порциями по 100,000 строк для экономии памяти при работе с большими объемами данных.
*   **Нормализованная структура базы данных**: Справочные данные (названия стран и TNVED) хранятся в отдельных таблицах, что:
    *   Уменьшает размер основной таблицы (названия не дублируются в каждой строке)
    *   Упрощает обновление справочников без изменения основной таблицы
    *   Позволяет DuckDB эффективно использовать индексы при JOIN'ах
    *   Оптимизирует работу с Superset, который эффективно обрабатывает JOIN'ы
*   **Ранжирование по периодам**: Колонка `period_rank` в представлении `unified_trade_data_enriched` позволяет эффективно фильтровать последние N месяцев для каждой комбинации страна-товар-направление (STRANA, TNVED, NAPR) без необходимости сложных подзапросов.

### Безопасность

*   **Проверка типов в SQL запросах**: При формировании SQL запросов к базе Comtrade выполняется явная проверка типов данных (M49 коды должны быть целыми числами) перед форматированием запроса, что предотвращает потенциальные проблемы с безопасностью.
*   **Валидация входных данных**: Все входные параметры проверяются на корректность типов перед использованием.

### Обработка выбросов

Обработка выбросов в колонке `KOL` вынесена в отдельный модуль `outlier_detection.py` для обеспечения разделения ответственности и гибкости процесса обработки данных.

*   **Разделение процессов**: Объединение данных и обработка выбросов теперь выполняются независимо, что позволяет:
    *   Запускать обработку выбросов отдельно от процесса объединения
    *   Повторно запускать обработку выбросов с разными параметрами без пересоздания базы данных
    *   Анализировать выбросы без изменения данных
*   **Использование модуля**: После объединения данных запустите модуль `outlier_detection.py` для обнаружения и обработки выбросов:
    ```bash
    python src/outlier_detection.py
    ```
*   **Методология**: Модуль использует ту же методологию обнаружения выбросов на основе трех независимых методов (абсолютные значения KOL, отношение KOL/STOIM, отношение KOL/NETTO) с параметрами из R-скрипта `outliers_detection.Rmd`.
*   **Подробная документация**: Полное описание методологии, параметров и использования модуля см. в `docs/outlier_detection-docs.md`.

### Обработка ошибок

При обнаружении ошибок валидации скрипт:
*   Логирует подробное сообщение об ошибке с указанием файла и типа проблемы.
*   Прекращает обработку проблемного файла и переходит к следующему.
*   Продолжает работу с остальными файлами, что позволяет получить максимально возможный результат даже при наличии проблемных данных.
