# -*- coding: utf-8 -*-
"""India Collector.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kPThia3K9zDXnMgF3fe0nHg0ctRQoNEB
"""

# -*- coding: utf-8 -*-
"""India Collector.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mzhYhIsSvui599ZREf4CFq7k5m3D4N3K
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
import numpy as np
from typing import Dict, Any, List, Optional
import logging
import os
import argparse
from datetime import datetime
from pathlib import Path

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Constants
BASE_URL = "https://tradestat.commerce.gov.in/meidb/"
EXPORT_URL = f"{BASE_URL}country_wise_all_commodities_export"
IMPORT_URL = f"{BASE_URL}country_wise_all_commodities_import"

USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
ACCEPT_HEADER = 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'
ACCEPT_LANGUAGE_HEADER = 'en-US,en;q=0.5'

DEFAULT_COUNTRY_CODE = 344
COMMODITY_LEVEL = 8
REPORT_YEAR_TYPE = 2


def fetch_meidb_data(session: requests.Session, url: str, data: Dict[str, Any], headers: Dict[str, str], retries: int = 3, backoff_factor: float = 0.5) -> pd.DataFrame:
    """
    Выполняет запрос к MEIDB и возвращает данные, с логикой повторных попыток.
    """
    for attempt in range(retries):
        try:
            response = session.post(url, data=data, headers=headers, timeout=30)
            response.raise_for_status()

            # Парсим HTML с результатами
            soup = BeautifulSoup(response.content, 'html.parser')

            # Ищем таблицу с данными
            table = soup.find('table', {'id': 'example1'})

            if not table:
                logging.warning(f"Таблица не найдена для {url}")
                return pd.DataFrame()

            # Извлекаем заголовки
            headers_list = []
            for th in table.find_all('th'):
                headers_list.append(th.get_text(strip=True).replace('\xa0', ' '))

            # Извлекаем данные
            rows_data = []
            for tr in table.find_all('tr')[1:]:  # Пропускаем строку заголовков
                cells = tr.find_all('td')
                if cells:
                    row_data = [cell.get_text(strip=True).replace('\xa0', ' ') for cell in cells]
                    rows_data.append(row_data)

            # Создаем DataFrame
            df = pd.DataFrame(rows_data, columns=headers_list)
            return df
        except requests.exceptions.RequestException as e:
            if attempt < retries - 1:
                sleep_time = backoff_factor * (2 ** attempt)
                logging.warning(f"Ошибка запроса: {e}. Повторная попытка {attempt + 1}/{retries} через {sleep_time:.2f} сек...")
                time.sleep(sleep_time)
            else:
                logging.error(f"Ошибка при выполнении запроса после {retries} попыток: {e}")
                return pd.DataFrame()
    return pd.DataFrame()


def process_trade_data(df: pd.DataFrame, flow_type: str, data_type: str) -> pd.DataFrame:
    """
    Обрабатывает данные торговли и возвращает обработанный DataFrame
    """
    if df.empty:
        return pd.DataFrame()

    # Находим нужные столбцы

    hs_col = next((col for col in df.columns if 'HSCode' in col or 'HS Code' in col), None)
    commodity_col = next((col for col in df.columns if 'Commodity' in col), None)

    # Находим столбец со значениями
    value_col = None
    value_cols = []
    for col in df.columns:
        if re.search(r'\w{3}-\d{4}', col) or re.search(r'\([RF]\)', col):
            value_cols.append(col)

    if not value_cols:
        logging.warning("Не удалось найти столбец с данными о стоимости")
        return pd.DataFrame()

    value_col = value_cols[1] if len(value_cols) > 1 else value_cols[0]

    if not all([hs_col, commodity_col, value_col]):
        logging.warning("Не удалось найти все необходимые столбцы")
        return pd.DataFrame()

    # Создаем базовый DataFrame с кодом и названием товара
    result_df = df[[hs_col, commodity_col]].copy()
    result_df.columns = ['HSCode', 'Commodity']

    # Обрабатываем значения в зависимости от типа данных
    if data_type == 'quantity':
        unit_col = next((col for col in df.columns if 'Unit' in col or 'UOM' in col), None)

        # Преобразуем в числовой формат, заменяя ошибки на NaN
        quantity_values = pd.to_numeric(df[value_col].str.replace(',', ''), errors='coerce')

        # ЗАМЕНЯЕМ ТОЛЬКО ДЛЯ QUANTITY: 0 на NaN
        quantity_values = quantity_values.replace(0, np.nan)

        result_df['Quantity'] = quantity_values

        if unit_col:
            result_df['Unit'] = df[unit_col]
            # Если количество NaN, то и единица измерения тоже должна быть NaN
            result_df.loc[result_df['Quantity'].isna(), 'Unit'] = np.nan
        else:
            result_df['Unit'] = 'Unknown'
            result_df.loc[result_df['Quantity'].isna(), 'Unit'] = np.nan
    elif data_type == 'usd':
        # ДЛЯ ДЕНЕЖНЫХ ДАННЫХ ОСТАВЛЯЕМ 0 КАК ЕСТЬ
        usd_values = pd.to_numeric(df[value_col].str.replace(',', ''), errors='coerce')
        result_df['USD'] = usd_values
    elif data_type == 'inr':
        # ДЛЯ ДЕНЕЖНЫХ ДАННЫХ ОСТАВЛЯЕМ 0 КАК ЕСТЬ
        inr_values = pd.to_numeric(df[value_col].str.replace(',', ''), errors='coerce')
        result_df['INR'] = inr_values

    result_df['Flow'] = flow_type
    return result_df

def get_trade_data_for_flow(year: int, month: int, country_code: int, flow_type: str) -> pd.DataFrame:
    """
    Получает все данные для указанного типа потока (экспорт/импорт)
    """
    # Определяем параметры в зависимости от типа торговли
    if flow_type == 'Ex':
        url = EXPORT_URL
        month_field = 'cwcexddMonth'
        year_field = 'cwcexddYear'
        country_field = 'cwcexallcount'
        commodity_level_field = 'cwcexddCommodityLevel'
        report_val_field = 'cwcexddReportVal'
        report_year_field = 'cwcexddReportYear'
        referer = EXPORT_URL
    else:
        url = IMPORT_URL
        month_field = 'cwcimMonth'
        year_field = 'cwcimYear'
        country_field = 'cwcimallcount'
        commodity_level_field = 'cwcimCommodityLevel'
        report_val_field = 'cwcimReportVal'
        report_year_field = 'cwcimReportYear'
        referer = IMPORT_URL

    results = []
    for data_type, report_val in [('usd', 1), ('inr', 3), ('quantity', 2)]:
        try:
            # Создаем новую сессию для каждого запроса
            session = requests.Session()

            # Получаем свежий CSRF-токен
            response_get = session.get(url, timeout=30)
            response_get.raise_for_status()
            soup = BeautifulSoup(response_get.content, 'html.parser')
            token_input = soup.find('input', {'name': '_token'})
            csrf_token = token_input.get('value') if token_input else None

            if not csrf_token:
                logging.warning(f"CSRF-токен не найден для {flow_type} ({data_type})")
                continue

            headers = {
                'User-Agent': USER_AGENT,
                'Accept': ACCEPT_HEADER,
                'Accept-Language': ACCEPT_LANGUAGE_HEADER,
                'Referer': referer,
            }

            data = {
                month_field: month,
                year_field: year,
                country_field: country_code,
                commodity_level_field: COMMODITY_LEVEL,
                report_val_field: report_val,
                report_year_field: REPORT_YEAR_TYPE,
                '_token': csrf_token
            }

            logging.info(f"Получение данных {flow_type} для типа {data_type}...")
            df = fetch_meidb_data(session, url, data, headers)

            if not df.empty:
                processed_df = process_trade_data(df, flow_type, data_type)
                if not processed_df.empty:
                    results.append(processed_df)

            time.sleep(2)  # Пауза между запросами

        except Exception as e:
            logging.error(f"Ошибка при получении данных для {flow_type} ({data_type}): {e}")
            continue

    # Объединяем все результаты для этого потока
    if results:
        # Начинаем с первого DataFrame
        result_df = results[0]

        # Последовательно объединяем с остальными
        for i in range(1, len(results)):
            result_df = result_df.merge(
                results[i],
                on=['HSCode', 'Commodity', 'Flow'],
                how='outer'
            )

        # Добавляем информацию о годе и месяце
        result_df['Year'] = year
        result_df['Month'] = month

        return result_df

    return pd.DataFrame()


def get_all_trade_data(year: int, month: int, country_code: int = DEFAULT_COUNTRY_CODE) -> pd.DataFrame:
    """
    Получает данные и для экспорта, и для импорта последовательно
    """
    logging.info("Сбор данных по экспорту...")
    export_df = get_trade_data_for_flow(year, month, country_code, 'Ex')

    logging.info("Сбор данных по импорту...")
    import_df = get_trade_data_for_flow(year, month, country_code, 'Im')

    all_dfs = []
    if not export_df.empty:
        all_dfs.append(export_df)
    if not import_df.empty:
        all_dfs.append(import_df)

    if not all_dfs:
        return pd.DataFrame()

    combined_df = pd.concat(all_dfs, ignore_index=True)

    combined_df = combined_df[combined_df.HSCode.apply(lambda x: x.isnumeric())]

    return post_process_data(combined_df) if not combined_df.empty else pd.DataFrame()

def post_process_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    Выполняет постобработку данных: переименование столбцов, создание новых и т.д.
    """
    df['USD'] = 1000 * df['USD']  # converting to thousand USD (prior - mln USD)

    df.Flow = df.Flow.apply(lambda x: 'ИМ' if x == 'Ex' else 'ЭК')

    rename_dict = {'HSCode': 'TNVED', 'USD': 'STOIM', 'Flow': 'NAPR', 'INR': 'STOIM_NAC_VAL',
                   'Quantity': 'KOL', 'Unit': 'EDIZM'}

    df.rename(columns=rename_dict, inplace=True)

    df.EDIZM = df.EDIZM.apply(lambda x: 'KGS' if x == 'KG' else x)

    df['NETTO'] = np.where(df.EDIZM == 'KGS', df.KOL, np.nan)

    df['TNVED2'] = df['TNVED'].apply(lambda x: x[0:2])
    df['TNVED4'] = df['TNVED'].apply(lambda x: x[0:4])
    df['TNVED6'] = df['TNVED'].apply(lambda x: x[0:6])

    df['PERIOD'] = pd.to_datetime(
        df["Year"].astype(str) + "-" + df["Month"].astype(str).str.zfill(2) + "-01"
    )

    df['STRANA'] = 'IN'

    return df


def save_india_data(df: pd.DataFrame, year: int, month: int, output_dir: Optional[Path] = None) -> None:
    """
    Сохраняет все данные Индии (импорт и экспорт вместе)
    в формате: data_raw/india/india_YYYY_MM.csv
    """
    if df.empty:
        logging.warning("Нет данных для сохранения.")
        return

    try:
        project_root = Path(__file__).resolve().parent.parent.parent
    except NameError:
        project_root = Path(os.getcwd())

    if output_dir is None:
        output_dir = project_root / 'data_raw' / 'india_new'

    output_dir.mkdir(parents=True, exist_ok=True)


    month_str = str(month).zfill(2)
    filename = f"india_{year}_{month_str}.csv"
    save_path = output_dir / filename


    df.to_csv(save_path, index=False, encoding='utf-8-sig')

    logging.info(f"Данные сохранены: {save_path}")

def main():
    """
    Основная функция для сбора данных.
    """
    parser = argparse.ArgumentParser(description="Сбор данных о торговле Индии.")
    parser.add_argument('--year', type=int, help="Год для сбора данных (если указан, --month тоже обязателен).")
    parser.add_argument('--month', type=int, help="Месяц для сбора данных (если указан, --year тоже обязателен).")
    parser.add_argument('--start_year', type=int, default=None, help="Начальный год для сбора данных.")
    parser.add_argument('--start_month', type=int, default=None, help="Начальный месяц для сбора данных.")
    parser.add_argument('--end_year', type=int, default=None, help="Конечный год для сбора данных.")
    parser.add_argument('--end_month', type=int, default=None, help="Конечный месяц для сбора данных.")
    args = parser.parse_args()

    now = datetime.now()

    if args.year and args.month:
        dates = [(args.year, args.month)]
    elif args.year or args.month:
        parser.error("--year и --month должны быть указаны вместе.")
        return
    else:
        start_year = args.start_year if args.start_year is not None else 2018
        start_month = args.start_month if args.start_month is not None else 1

        end_year = args.end_year if args.end_year is not None else now.year

        if args.end_month is not None:
            end_month = args.end_month
        else:
            if args.end_year is None or args.end_year == now.year:
                end_month = now.month
            else:
                end_month = 12

        dates = []
        for year in range(start_year, end_year + 1):
            s_month = start_month if year == start_year else 1
            e_month = end_month if year == end_year else 12
            for month in range(s_month, e_month + 1):
                dates.append((year, month))

    for (year, month) in dates:
        logging.info(f"Начало парсинга данных за {year}-{month:02d}...")
        combined_data = get_all_trade_data(year, month, DEFAULT_COUNTRY_CODE)

        if not combined_data.empty:
            logging.info(f"Данные успешно получены: {combined_data['Year'].iloc[0]}_{combined_data['Month'].iloc[0]:02d}")
            logging.info(combined_data.head())

            save_india_data(combined_data, year, month)
            logging.info(f"\nДанные сохранены")
        else:
            logging.warning(f"Не удалось получить данные за {year}-{month:02d}")

if __name__ == "__main__":
    main()